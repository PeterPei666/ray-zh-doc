

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Using Ray with GPUs &mdash; Ray 0.3.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="Ray 0.3.0 documentation" href="index.html"/>
        <link rel="next" title="Ray.tune: Hyperparameter Optimization Framework" href="tune.html"/>
        <link rel="prev" title="Actors" href="actors.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> Ray
          

          
          </a>

          
            
            
              <div class="version">
                0.3.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="install-on-ubuntu.html">Installation on Ubuntu</a></li>
<li class="toctree-l1"><a class="reference internal" href="install-on-macosx.html">Installation on Mac OS X</a></li>
<li class="toctree-l1"><a class="reference internal" href="install-on-docker.html">Installation on Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation-troubleshooting.html">Installation Troubleshooting</a></li>
</ul>
<p class="caption"><span class="caption-text">Getting Started</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">The Ray API</a></li>
<li class="toctree-l1"><a class="reference internal" href="actors.html">Actors</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Using Ray with GPUs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#starting-ray-with-gpus">Starting Ray with GPUs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-remote-functions-with-gpus">Using Remote Functions with GPUs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-actors-with-gpus">Using Actors with GPUs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#troubleshooting">Troubleshooting</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tune.html">Ray.tune: Hyperparameter Optimization Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="rllib.html">Ray RLlib: A Scalable Reinforcement Learning Library</a></li>
<li class="toctree-l1"><a class="reference internal" href="rllib-dev.html">RLlib Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="webui.html">Web UI</a></li>
</ul>
<p class="caption"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="example-hyperopt.html">Hyperparameter Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="example-rl-pong.html">Learning to Play Pong</a></li>
<li class="toctree-l1"><a class="reference internal" href="example-policy-gradient.html">Policy Gradient Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="example-parameter-server.html">Parameter Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="example-resnet.html">ResNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="example-a3c.html">Asynchronous Advantage Actor Critic (A3C)</a></li>
<li class="toctree-l1"><a class="reference internal" href="example-lbfgs.html">Batch L-BFGS</a></li>
<li class="toctree-l1"><a class="reference internal" href="example-evolution-strategies.html">Evolution Strategies</a></li>
<li class="toctree-l1"><a class="reference internal" href="example-cython.html">Cython</a></li>
<li class="toctree-l1"><a class="reference internal" href="example-streaming.html">Streaming MapReduce</a></li>
<li class="toctree-l1"><a class="reference internal" href="using-ray-with-tensorflow.html">Using Ray with TensorFlow</a></li>
</ul>
<p class="caption"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="internals-overview.html">An Overview of the Internals</a></li>
<li class="toctree-l1"><a class="reference internal" href="serialization.html">Serialization in the Object Store</a></li>
<li class="toctree-l1"><a class="reference internal" href="fault-tolerance.html">Fault Tolerance</a></li>
<li class="toctree-l1"><a class="reference internal" href="plasma-object-store.html">The Plasma Object Store</a></li>
<li class="toctree-l1"><a class="reference internal" href="resources.html">Resource (CPUs, GPUs)</a></li>
</ul>
<p class="caption"><span class="caption-text">Cluster Usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="autoscaling.html">Cloud Setup and Auto-Scaling</a></li>
<li class="toctree-l1"><a class="reference internal" href="using-ray-on-a-cluster.html">Using Ray on a Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="using-ray-on-a-large-cluster.html">Using Ray on a Large Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="using-ray-and-docker-on-a-cluster.html">Using Ray and Docker on a Cluster (EXPERIMENTAL)</a></li>
</ul>
<p class="caption"><span class="caption-text">Help</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="contact.html">Contact</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Ray</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Using Ray with GPUs</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/using-ray-with-gpus.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="using-ray-with-gpus">
<h1>Using Ray with GPUs<a class="headerlink" href="#using-ray-with-gpus" title="Permalink to this headline">¶</a></h1>
<p>GPUs are critical for many machine learning applications. Ray enables remote
functions and actors to specify their GPU requirements in the <code class="docutils literal"><span class="pre">ray.remote</span></code>
decorator.</p>
<div class="section" id="starting-ray-with-gpus">
<h2>Starting Ray with GPUs<a class="headerlink" href="#starting-ray-with-gpus" title="Permalink to this headline">¶</a></h2>
<p>In order for remote functions and actors to use GPUs, Ray must know how many
GPUs are available. If you are starting Ray on a single machine, you can specify
the number of GPUs as follows.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">ray</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">num_gpus</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<p>If you don’t pass in the <code class="docutils literal"><span class="pre">num_gpus</span></code> argument, Ray will assume that there are 0
GPUs on the machine.</p>
<p>If you are starting Ray with the <code class="docutils literal"><span class="pre">ray</span> <span class="pre">start</span></code> command, you can indicate the
number of GPUs on the machine with the <code class="docutils literal"><span class="pre">--num-gpus</span></code> argument.</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>ray start --head --num-gpus<span class="o">=</span><span class="m">4</span>
</pre></div>
</div>
<p><strong>Note:</strong> There is nothing preventing you from passing in a larger value of
<code class="docutils literal"><span class="pre">num_gpus</span></code> than the true number of GPUs on the machine. In this case, Ray will
act as if the machine has the number of GPUs you specified for the purposes of
scheduling tasks that require GPUs. Trouble will only occur if those tasks
attempt to actually use GPUs that don’t exist.</p>
</div>
<div class="section" id="using-remote-functions-with-gpus">
<h2>Using Remote Functions with GPUs<a class="headerlink" href="#using-remote-functions-with-gpus" title="Permalink to this headline">¶</a></h2>
<p>If a remote function requires GPUs, indicate the number of required GPUs in the
remote decorator.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="nd">@ray.remote</span><span class="p">(</span><span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">gpu_method</span><span class="p">():</span>
    <span class="k">return</span> <span class="s2">&quot;This function is allowed to use GPUs {}.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">get_gpu_ids</span><span class="p">())</span>
</pre></div>
</div>
<p>Inside of the remote function, a call to <code class="docutils literal"><span class="pre">ray.get_gpu_ids()</span></code> will return a
list of integers indicating which GPUs the remote function is allowed to use.</p>
<p><strong>Note:</strong> The function <code class="docutils literal"><span class="pre">gpu_method</span></code> defined above doesn’t actually use any
GPUs. Ray will schedule it on a machine which has at least one GPU, and will
reserve one GPU for it while it is being executed, however it is up to the
function to actually make use of the GPU. This is typically done through an
external library like TensorFlow. Here is an example that actually uses GPUs.
Note that for this example to work, you will need to install the GPU version of
TensorFlow.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>

<span class="nd">@ray.remote</span><span class="p">(</span><span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">gpu_method</span><span class="p">():</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">ray</span><span class="o">.</span><span class="n">get_gpu_ids</span><span class="p">()))</span>
    <span class="c1"># Create a TensorFlow session. TensorFlow will restrict itself to use the</span>
    <span class="c1"># GPUs specified by the CUDA_VISIBLE_DEVICES environment variable.</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Note:</strong> It is certainly possible for the person implementing <code class="docutils literal"><span class="pre">gpu_method</span></code> to
ignore <code class="docutils literal"><span class="pre">ray.get_gpu_ids</span></code> and to use all of the GPUs on the machine. Ray does
not prevent this from happening, and this can lead to too many workers using the
same GPU at the same time. For example, if the <code class="docutils literal"><span class="pre">CUDA_VISIBLE_DEVICES</span></code>
environment variable is not set, then TensorFlow will attempt to use all of the
GPUs on the machine.</p>
</div>
<div class="section" id="using-actors-with-gpus">
<h2>Using Actors with GPUs<a class="headerlink" href="#using-actors-with-gpus" title="Permalink to this headline">¶</a></h2>
<p>When defining an actor that uses GPUs, indicate the number of GPUs an actor
instance requires in the <code class="docutils literal"><span class="pre">ray.remote</span></code> decorator.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="nd">@ray.remote</span><span class="p">(</span><span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">GPUActor</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;This actor is allowed to use GPUs {}.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">get_gpu_ids</span><span class="p">())</span>
</pre></div>
</div>
<p>When the actor is created, GPUs will be reserved for that actor for the lifetime
of the actor.</p>
<p>Note that Ray must have been started with at least as many GPUs as the number of
GPUs you pass into the <code class="docutils literal"><span class="pre">ray.remote</span></code> decorator. Otherwise, if you pass in a
number greater than what was passed into <code class="docutils literal"><span class="pre">ray.init</span></code>, an exception will be
thrown when instantiating the actor.</p>
<p>The following is an example of how to use GPUs in an actor through TensorFlow.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="nd">@ray.remote</span><span class="p">(</span><span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">GPUActor</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gpu_ids</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get_gpu_ids</span><span class="p">()</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gpu_ids</span><span class="p">))</span>
        <span class="c1"># The call to tf.Session() will restrict TensorFlow to use the GPUs</span>
        <span class="c1"># specified in the CUDA_VISIBLE_DEVICES environment variable.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="troubleshooting">
<h2>Troubleshooting<a class="headerlink" href="#troubleshooting" title="Permalink to this headline">¶</a></h2>
<p><strong>Note:</strong> Currently, when a worker executes a task that uses a GPU, the task may
allocate memory on the GPU and may not release it when the task finishes
executing. This can lead to problems. See <a class="reference external" href="https://github.com/ray-project/ray/issues/616">this issue</a>.</p>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="tune.html" class="btn btn-neutral float-right" title="Ray.tune: Hyperparameter Optimization Framework" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="actors.html" class="btn btn-neutral" title="Actors" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, The Ray Team.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.3.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>